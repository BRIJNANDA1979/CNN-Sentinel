{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Edusat_Data_8_classes 15_May_2021_Version_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1rl0_0AxGrHEUaq8pi-vNW80uJxtFM_Tx",
      "authorship_tag": "ABX9TyMDwVnlwJdrTr4ZBtpPcRjp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BRIJNANDA1979/CNN-Sentinel/blob/master/CNN_Edusat_Data_8_classes_15_May_2021_Version_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PdKw1IFO_kG",
        "outputId": "c7d11de4-7fb5-492b-a4b2-e5920dcff708"
      },
      "source": [
        "\"\"\"\n",
        "Created on Thu May 13 03:02:04 2021\n",
        "\n",
        "@author: BRIJB\n",
        "\"\"\"\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# import the needed packages\n",
        "import tensorflow as tf\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import tensorflow.keras as keras\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from keras.models import model_from_json\n",
        "import os\n",
        "\n",
        "batch_size = 30\n",
        "\n",
        "# define and move to dataset directory\n",
        "datasetdir = \"/content/drive/MyDrive/Data/Sentinel 2 Data for CNN/EuroSAT/2750\"\n",
        "import os\n",
        "os.chdir(datasetdir)\n",
        "\n",
        "\n",
        "\n",
        "# shortcut to the ImageDataGenerator class\n",
        "ImageDataGenerator = keras.preprocessing.image.ImageDataGenerator\n",
        "gen = ImageDataGenerator()\n",
        "iterator = gen.flow_from_directory(\n",
        "    os.getcwd(), \n",
        "    target_size=(256,256), \n",
        "    classes=('Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential','SeaLake')\n",
        "    \n",
        ")\n",
        "# we can guess that the iterator has a next function, \n",
        "# because all python iterators have one. \n",
        "batch = iterator.next()\n",
        "print(len(batch))\n",
        "print(type(batch[0]))\n",
        "print(batch[0].shape)\n",
        "print(batch[0].dtype)\n",
        "#print(batch[0].max())\n",
        "#print(batch[1].shape)\n",
        "#print(batch[1].dtype)\n",
        "#print(type(batch[1]))\n",
        "#the first element is an array of 32 images with 64X64 pixels, and 3 color channels, encoded as floats in the range 0 to 255\n",
        "#The second element contains the 32 corresponding labels.\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 16579 images belonging to 8 classes.\n",
            "2\n",
            "<class 'numpy.ndarray'>\n",
            "(32, 256, 256, 3)\n",
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4jLiUltPUGm",
        "outputId": "e3ad51d5-96a2-4d69-adac-87bc3e9b5674"
      },
      "source": [
        "batch = iterator.next()\n",
        "print(len(batch))\n",
        "print(type(batch[1]))\n",
        "print(batch[1].shape)\n",
        "print(batch[1].dtype)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "<class 'numpy.ndarray'>\n",
            "(32, 8)\n",
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUm4Y-MHQJVD",
        "outputId": "069574b2-4730-49cf-d0e7-a9171e67a709"
      },
      "source": [
        "#Augmentation by Flipping images\n",
        "#Now, let's make the transformation a bit more complex. This time, the ImageDataGenerator will flip, zoom, and rotate the images on a random basis   \n",
        "imgdatagen = ImageDataGenerator(\n",
        "    rescale = 1/255., \n",
        "    horizontal_flip = True, \n",
        "    zoom_range = 0.3, \n",
        "    rotation_range = 15.,\n",
        "    validation_split = 0.1,\n",
        ")\n",
        "batch_size = 30\n",
        "height, width = (256,256)\n",
        "train_dataset = imgdatagen.flow_from_directory(\n",
        "    os.getcwd(),\n",
        "    target_size = (height, width), \n",
        "    classes = ('Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential','SeaLake'),\n",
        "    batch_size = batch_size,\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "val_dataset = imgdatagen.flow_from_directory(\n",
        "    os.getcwd(),\n",
        "    target_size = (height, width), \n",
        "    classes = ('Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential','SeaLake'),\n",
        "    batch_size = batch_size,\n",
        "    subset = 'validation'\n",
        ")\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "initializers = {\n",
        "    \n",
        "}\n",
        "model.add( \n",
        "    keras.layers.Conv2D(\n",
        "        24, 5, input_shape=(256,256,3), \n",
        "        activation='relu', \n",
        "    )\n",
        ")\n",
        "model.add( keras.layers.MaxPooling2D(2) )\n",
        "model.add( \n",
        "    keras.layers.Conv2D(\n",
        "        48, 5, activation='relu', \n",
        "    )\n",
        ")\n",
        "model.add( keras.layers.MaxPooling2D(2) )\n",
        "model.add( \n",
        "    keras.layers.Conv2D(\n",
        "        96, 5, activation='relu', \n",
        "    )\n",
        ")\n",
        "model.add( keras.layers.Flatten() )\n",
        "model.add( keras.layers.Dropout(0.2) )\n",
        "\n",
        "model.add( keras.layers.Dense(\n",
        "    8, activation='softmax',\n",
        "    )\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=keras.optimizers.RMSprop(lr=0.001),\n",
        "              metrics=['acc'])\n",
        "\n",
        "model.fit_generator(\n",
        "    train_dataset, \n",
        "    validation_data = val_dataset,\n",
        "    workers=10,\n",
        "    epochs=5,\n",
        ")\n",
        "\n",
        "# serialize model to JSON https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14922 images belonging to 8 classes.\n",
            "Found 1657 images belonging to 8 classes.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 252, 252, 24)      1824      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 126, 126, 24)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 122, 122, 48)      28848     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 61, 61, 48)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 57, 57, 96)        115296    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 311904)            0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 311904)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 2495240   \n",
            "=================================================================\n",
            "Total params: 2,641,208\n",
            "Trainable params: 2,641,208\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            " 68/498 [===>..........................] - ETA: 38:16 - loss: 1.3952 - acc: 0.1850"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6be5epD00-U"
      },
      "source": [
        "ADDING VGG16\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssI7QgfU067W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ndTMfQDqfNl"
      },
      "source": [
        "from keras.applications import vgg16\n",
        "conv_base = vgg16.VGG16(include_top=False,\n",
        "            input_shape = (256,256,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abYiLuCOrJRW"
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMHCTYCTrsot"
      },
      "source": [
        "len(conv_base.trainable_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxDxjyeArw3i"
      },
      "source": [
        "#https://www.tensorflow.org/guide/keras/transfer_learning#introduction  on freezing weights of pretrained model\n",
        "# freeze the weights\n",
        "for layer in conv_base.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkSYmFxer2-Z"
      },
      "source": [
        "# now there are 0\n",
        "len(conv_base.trainable_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obuIF62ysL2z"
      },
      "source": [
        "model_file = '/content/drive/MyDrive/Data/Sentinel 2 Data for CNN/Code/model.h5'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trr9PqTRsmuZ"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(conv_base)\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(512, activation='relu'))\n",
        "model.add(keras.layers.Dense(8, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTSx-z3Xvjk2"
      },
      "source": [
        "#Augmentation by Flipping images\n",
        "#Now, let's make the transformation a bit more complex. This time, the ImageDataGenerator will flip, zoom, and rotate the images on a random basis   \n",
        "imgdatagen = ImageDataGenerator(\n",
        "    rescale = 1/255., \n",
        "    horizontal_flip = True, \n",
        "    zoom_range = 0.3, \n",
        "    rotation_range = 15.,\n",
        "    validation_split = 0.1,\n",
        ")\n",
        "batch_size = 30\n",
        "height, width = (256,256)\n",
        "train_dataset = imgdatagen.flow_from_directory(\n",
        "    os.getcwd(),\n",
        "    target_size = (height, width), \n",
        "    classes = ('Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential','SeaLake'),\n",
        "    batch_size = batch_size,\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "val_dataset = imgdatagen.flow_from_directory(\n",
        "    os.getcwd(),\n",
        "    target_size = (height, width), \n",
        "    classes = ('Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential','SeaLake'),\n",
        "    batch_size = batch_size,\n",
        "    subset = 'validation'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwwY660PvAyW"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=keras.optimizers.RMSprop(lr=0.001),\n",
        "              metrics=['acc'])\n",
        "\n",
        "model.fit_generator(\n",
        "    train_dataset, \n",
        "    validation_data = val_dataset,\n",
        "    workers=10,\n",
        "    epochs=5,\n",
        ")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYZi8n7brVBw"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sun May 16 10:10:57 2021\n",
        "\n",
        "@author: BRIJB\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import os, fnmatch, urllib.request\n",
        "import pandas as pd\n",
        "import json, time\n",
        "import matplotlib.pyplot as plt\n",
        "#from gdalRead import gdalRead\n",
        "\n",
        "# In order to read many images via the _vsicurl_ driver, please use the command _gdal.VSICurlClearCache()_ after every _gdalRead_ command.\n",
        "\n",
        "import numpy as np\n",
        "from osgeo import gdal, osr\n",
        "import os\n",
        "os.environ[\"GDAL_HTTP_MULTIRANGE\"]=\"SERIAL\"\n",
        "\n",
        "def gdalRead(infile):\n",
        "    src = gdal.Open(infile)\n",
        "    if infile.split('.')[-1] in ['jpg', 'png']:\n",
        "        Info = {\n",
        "                    'projection': '-',\n",
        "                    'geotransform': '-',\n",
        "                    'EPSG': '-',\n",
        "                    'datatype': gdal.GetDataTypeName(src.GetRasterBand(1).DataType),\n",
        "                    'columns': src.RasterXSize,\n",
        "                    'rows': src.RasterYSize,\n",
        "                    'numofbands': src.RasterCount\n",
        "                }\n",
        "    else:\n",
        "        proj = osr.SpatialReference(wkt=src.GetProjection())\n",
        "        Info = {\n",
        "                    'projection': src.GetProjection(),\n",
        "                    'geotransform': src.GetGeoTransform(),\n",
        "                    'EPSG': proj.GetAttrValue('AUTHORITY',1),\n",
        "                    'datatype': gdal.GetDataTypeName(src.GetRasterBand(1).DataType),\n",
        "                    'columns': src.RasterXSize,\n",
        "                    'rows': src.RasterYSize,\n",
        "                    'numofbands': src.RasterCount\n",
        "                }\n",
        "    Image = np.zeros((src.RasterYSize, src.RasterXSize, src.RasterCount), dtype=NP2GDAL_CONVERSION[Info['datatype']])\n",
        "    for band in range(Image.shape[2]):\n",
        "        Image[:,:,band] = src.GetRasterBand(band+1).ReadAsArray()\n",
        "    del src\n",
        "    gdal.VSICurlClearCache()\n",
        "    return Info, np.squeeze(Image)\n",
        "\n",
        "NP2GDAL_CONVERSION = {\n",
        "  \"Byte\": np.uint8,\n",
        "  \"UInt16\": np.uint16  \n",
        "}\n",
        "mainfolder = 'https://jeodpp.jrc.ec.europa.eu/ftp/public/MachineLearning/SatImNet'\n",
        "collection = 'BigEarthNet-v1.0'\n",
        "\n",
        "df = pd.read_json(os.path.join(mainfolder, 'Table.json'))\n",
        "cols = list(df.columns)\n",
        "cols.remove('Feature')\n",
        "df = df[['Feature']+cols]\n",
        "df\n",
        "# Read specific info for BigEarthNet-v1.0\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "try: df.set_index('Feature', inplace=True);\n",
        "except: pass\n",
        "df[[collection]]\n",
        "with urllib.request.urlopen(os.path.join(mainfolder, collection, 'content_public.json')) as f:\n",
        "    content = json.loads(f.read().decode())\n",
        "classes = content['classes']\n",
        "print(classes)\n",
        "infile = '/vsizip//vsicurl/https://jeodpp.jrc.ec.europa.eu/ftp/public/MachineLearning/SatImNet/BigEarthNet-v1.0/2017/07/201707_10.zip/S2A_MSIL2A_20170704T112111_10_20/S2A_MSIL2A_20170704T112111_10_20_B05.tif'\n",
        "Info, I = gdalRead(infile)\n",
        "Info\n",
        "gdal.VSICurlClearCache()\n",
        "# Display images\n",
        "fig, axarr = plt.subplots(1, 1, figsize=(6, 6))\n",
        "axarr.axis('off')\n",
        "axarr.imshow(I)\n",
        "plt.tight_layout(h_pad=0.1, w_pad=0.1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}