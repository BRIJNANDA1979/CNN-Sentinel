{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Edusat_Data_8_classes 15_May_2021_Version_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1rl0_0AxGrHEUaq8pi-vNW80uJxtFM_Tx",
      "authorship_tag": "ABX9TyMDwVnlwJdrTr4ZBtpPcRjp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BRIJNANDA1979/CNN-Sentinel/blob/master/CNN_Edusat_Data_8_classes_15_May_2021_Version_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PdKw1IFO_kG",
        "outputId": "5d7f83e3-bf95-41a7-ac24-0e5a17d2c58d"
      },
      "source": [
        "\"\"\"\n",
        "Created on Thu May 13 03:02:04 2021\n",
        "\n",
        "@author: BRIJB\n",
        "\"\"\"\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# import the needed packages\n",
        "import tensorflow as tf\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import tensorflow.keras as keras\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from keras.models import model_from_json\n",
        "import os\n",
        "\n",
        "batch_size = 30\n",
        "\n",
        "# define and move to dataset directory\n",
        "datasetdir = \"/content/drive/MyDrive/Data/Sentinel 2 Data for CNN/EuroSAT/2750\"\n",
        "import os\n",
        "os.chdir(datasetdir)\n",
        "\n",
        "\n",
        "\n",
        "# shortcut to the ImageDataGenerator class\n",
        "ImageDataGenerator = keras.preprocessing.image.ImageDataGenerator\n",
        "gen = ImageDataGenerator()\n",
        "iterator = gen.flow_from_directory(\n",
        "    os.getcwd(), \n",
        "    target_size=(256,256), \n",
        "    classes=('Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential','SeaLake')\n",
        "    \n",
        ")\n",
        "# we can guess that the iterator has a next function, \n",
        "# because all python iterators have one. \n",
        "batch = iterator.next()\n",
        "print(len(batch))\n",
        "print(type(batch[0]))\n",
        "print(batch[0].shape)\n",
        "print(batch[0].dtype)\n",
        "#print(batch[0].max())\n",
        "#print(batch[1].shape)\n",
        "#print(batch[1].dtype)\n",
        "#print(type(batch[1]))\n",
        "#the first element is an array of 32 images with 64X64 pixels, and 3 color channels, encoded as floats in the range 0 to 255\n",
        "#The second element contains the 32 corresponding labels.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 16579 images belonging to 8 classes.\n",
            "2\n",
            "<class 'numpy.ndarray'>\n",
            "(32, 256, 256, 3)\n",
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4jLiUltPUGm",
        "outputId": "78e15cf9-b7e7-4fa9-b445-03b99c244002"
      },
      "source": [
        "batch = iterator.next()\n",
        "print(len(batch))\n",
        "print(type(batch[1]))\n",
        "print(batch[1].shape)\n",
        "print(batch[1].dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "<class 'numpy.ndarray'>\n",
            "(32, 8)\n",
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUm4Y-MHQJVD",
        "outputId": "43e8ff87-1c1d-4277-92ff-609f44dc52c2"
      },
      "source": [
        "#Augmentation by Flipping images\n",
        "#Now, let's make the transformation a bit more complex. This time, the ImageDataGenerator will flip, zoom, and rotate the images on a random basis   \n",
        "imgdatagen = ImageDataGenerator(\n",
        "    rescale = 1/255., \n",
        "    horizontal_flip = True, \n",
        "    zoom_range = 0.3, \n",
        "    rotation_range = 15.,\n",
        "    validation_split = 0.1,\n",
        ")\n",
        "batch_size = 30\n",
        "height, width = (256,256)\n",
        "train_dataset = imgdatagen.flow_from_directory(\n",
        "    os.getcwd(),\n",
        "    target_size = (height, width), \n",
        "    classes = ('Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential','SeaLake'),\n",
        "    batch_size = batch_size,\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "val_dataset = imgdatagen.flow_from_directory(\n",
        "    os.getcwd(),\n",
        "    target_size = (height, width), \n",
        "    classes = ('Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential','SeaLake'),\n",
        "    batch_size = batch_size,\n",
        "    subset = 'validation'\n",
        ")\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "initializers = {\n",
        "    \n",
        "}\n",
        "model.add( \n",
        "    keras.layers.Conv2D(\n",
        "        24, 5, input_shape=(256,256,3), \n",
        "        activation='relu', \n",
        "    )\n",
        ")\n",
        "model.add( keras.layers.MaxPooling2D(2) )\n",
        "model.add( \n",
        "    keras.layers.Conv2D(\n",
        "        48, 5, activation='relu', \n",
        "    )\n",
        ")\n",
        "model.add( keras.layers.MaxPooling2D(2) )\n",
        "model.add( \n",
        "    keras.layers.Conv2D(\n",
        "        96, 5, activation='relu', \n",
        "    )\n",
        ")\n",
        "model.add( keras.layers.Flatten() )\n",
        "model.add( keras.layers.Dropout(0.2) )\n",
        "\n",
        "model.add( keras.layers.Dense(\n",
        "    8, activation='softmax',\n",
        "    )\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=keras.optimizers.RMSprop(lr=0.001),\n",
        "              metrics=['acc'])\n",
        "\n",
        "model.fit_generator(\n",
        "    train_dataset, \n",
        "    validation_data = val_dataset,\n",
        "    workers=10,\n",
        "    epochs=5,\n",
        ")\n",
        "\n",
        "# serialize model to JSON https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14922 images belonging to 8 classes.\n",
            "Found 1657 images belonging to 8 classes.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 252, 252, 24)      1824      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 126, 126, 24)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 122, 122, 48)      28848     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 61, 61, 48)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 57, 57, 96)        115296    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 311904)            0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 311904)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 2495240   \n",
            "=================================================================\n",
            "Total params: 2,641,208\n",
            "Trainable params: 2,641,208\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "498/498 [==============================] - 2754s 6s/step - loss: 0.5864 - acc: 0.3314 - val_loss: 0.2650 - val_acc: 0.5474\n",
            "Epoch 2/5\n",
            "498/498 [==============================] - 2654s 5s/step - loss: 0.2651 - acc: 0.5334 - val_loss: 0.2469 - val_acc: 0.5836\n",
            "Epoch 3/5\n",
            "107/498 [=====>........................] - ETA: 33:25 - loss: 0.2799 - acc: 0.5961"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6be5epD00-U"
      },
      "source": [
        "ADDING VGG16\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssI7QgfU067W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ndTMfQDqfNl",
        "outputId": "c07fe1fa-439d-4d53-baf2-f494337847bb"
      },
      "source": [
        "from keras.applications import vgg16\n",
        "conv_base = vgg16.VGG16(include_top=False,\n",
        "            input_shape = (256,256,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abYiLuCOrJRW",
        "outputId": "83d7e6e3-985b-4e61-8fb6-eb95971ce747"
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMHCTYCTrsot",
        "outputId": "5772b923-9521-4e0a-9c73-02dd89d898b6"
      },
      "source": [
        "len(conv_base.trainable_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxDxjyeArw3i"
      },
      "source": [
        "#https://www.tensorflow.org/guide/keras/transfer_learning#introduction  on freezing weights of pretrained model\n",
        "# freeze the weights\n",
        "for layer in conv_base.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkSYmFxer2-Z",
        "outputId": "15aef269-8bc3-4195-93fe-a52f498f243d"
      },
      "source": [
        "# now there are 0\n",
        "len(conv_base.trainable_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obuIF62ysL2z"
      },
      "source": [
        "model_file = '/content/drive/MyDrive/Data/Sentinel 2 Data for CNN/Code/model.h5'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trr9PqTRsmuZ",
        "outputId": "9354e460-3bf4-46ab-8cfa-9821850dd810"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(conv_base)\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(512, activation='relu'))\n",
        "model.add(keras.layers.Dense(8, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 8, 8, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               16777728  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 4104      \n",
            "=================================================================\n",
            "Total params: 31,496,520\n",
            "Trainable params: 16,781,832\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTSx-z3Xvjk2",
        "outputId": "6882d414-656e-45eb-8fa8-c5bdc198e3e0"
      },
      "source": [
        "#Augmentation by Flipping images\n",
        "#Now, let's make the transformation a bit more complex. This time, the ImageDataGenerator will flip, zoom, and rotate the images on a random basis   \n",
        "imgdatagen = ImageDataGenerator(\n",
        "    rescale = 1/255., \n",
        "    horizontal_flip = True, \n",
        "    zoom_range = 0.3, \n",
        "    rotation_range = 15.,\n",
        "    validation_split = 0.1,\n",
        ")\n",
        "batch_size = 30\n",
        "height, width = (256,256)\n",
        "train_dataset = imgdatagen.flow_from_directory(\n",
        "    os.getcwd(),\n",
        "    target_size = (height, width), \n",
        "    classes = ('Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential','SeaLake'),\n",
        "    batch_size = batch_size,\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "val_dataset = imgdatagen.flow_from_directory(\n",
        "    os.getcwd(),\n",
        "    target_size = (height, width), \n",
        "    classes = ('Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential','SeaLake'),\n",
        "    batch_size = batch_size,\n",
        "    subset = 'validation'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14922 images belonging to 8 classes.\n",
            "Found 1657 images belonging to 8 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwwY660PvAyW",
        "outputId": "fe03b62e-9276-4b1e-e5b2-49cb0b4dae1b"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=keras.optimizers.RMSprop(lr=0.001),\n",
        "              metrics=['acc'])\n",
        "\n",
        "model.fit_generator(\n",
        "    train_dataset, \n",
        "    validation_data = val_dataset,\n",
        "    workers=10,\n",
        "    epochs=5,\n",
        ")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "498/498 [==============================] - ETA: 0s - loss: 0.5870 - acc: 0.5252 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYZi8n7brVBw"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sun May 16 10:10:57 2021\n",
        "\n",
        "@author: BRIJB\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import os, fnmatch, urllib.request\n",
        "import pandas as pd\n",
        "import json, time\n",
        "import matplotlib.pyplot as plt\n",
        "#from gdalRead import gdalRead\n",
        "\n",
        "# In order to read many images via the _vsicurl_ driver, please use the command _gdal.VSICurlClearCache()_ after every _gdalRead_ command.\n",
        "\n",
        "import numpy as np\n",
        "from osgeo import gdal, osr\n",
        "import os\n",
        "os.environ[\"GDAL_HTTP_MULTIRANGE\"]=\"SERIAL\"\n",
        "\n",
        "def gdalRead(infile):\n",
        "    src = gdal.Open(infile)\n",
        "    if infile.split('.')[-1] in ['jpg', 'png']:\n",
        "        Info = {\n",
        "                    'projection': '-',\n",
        "                    'geotransform': '-',\n",
        "                    'EPSG': '-',\n",
        "                    'datatype': gdal.GetDataTypeName(src.GetRasterBand(1).DataType),\n",
        "                    'columns': src.RasterXSize,\n",
        "                    'rows': src.RasterYSize,\n",
        "                    'numofbands': src.RasterCount\n",
        "                }\n",
        "    else:\n",
        "        proj = osr.SpatialReference(wkt=src.GetProjection())\n",
        "        Info = {\n",
        "                    'projection': src.GetProjection(),\n",
        "                    'geotransform': src.GetGeoTransform(),\n",
        "                    'EPSG': proj.GetAttrValue('AUTHORITY',1),\n",
        "                    'datatype': gdal.GetDataTypeName(src.GetRasterBand(1).DataType),\n",
        "                    'columns': src.RasterXSize,\n",
        "                    'rows': src.RasterYSize,\n",
        "                    'numofbands': src.RasterCount\n",
        "                }\n",
        "    Image = np.zeros((src.RasterYSize, src.RasterXSize, src.RasterCount), dtype=NP2GDAL_CONVERSION[Info['datatype']])\n",
        "    for band in range(Image.shape[2]):\n",
        "        Image[:,:,band] = src.GetRasterBand(band+1).ReadAsArray()\n",
        "    del src\n",
        "    gdal.VSICurlClearCache()\n",
        "    return Info, np.squeeze(Image)\n",
        "\n",
        "NP2GDAL_CONVERSION = {\n",
        "  \"Byte\": np.uint8,\n",
        "  \"UInt16\": np.uint16  \n",
        "}\n",
        "mainfolder = 'https://jeodpp.jrc.ec.europa.eu/ftp/public/MachineLearning/SatImNet'\n",
        "collection = 'BigEarthNet-v1.0'\n",
        "\n",
        "df = pd.read_json(os.path.join(mainfolder, 'Table.json'))\n",
        "cols = list(df.columns)\n",
        "cols.remove('Feature')\n",
        "df = df[['Feature']+cols]\n",
        "df\n",
        "# Read specific info for BigEarthNet-v1.0\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "try: df.set_index('Feature', inplace=True);\n",
        "except: pass\n",
        "df[[collection]]\n",
        "with urllib.request.urlopen(os.path.join(mainfolder, collection, 'content_public.json')) as f:\n",
        "    content = json.loads(f.read().decode())\n",
        "classes = content['classes']\n",
        "print(classes)\n",
        "infile = '/vsizip//vsicurl/https://jeodpp.jrc.ec.europa.eu/ftp/public/MachineLearning/SatImNet/BigEarthNet-v1.0/2017/07/201707_10.zip/S2A_MSIL2A_20170704T112111_10_20/S2A_MSIL2A_20170704T112111_10_20_B05.tif'\n",
        "Info, I = gdalRead(infile)\n",
        "Info\n",
        "gdal.VSICurlClearCache()\n",
        "# Display images\n",
        "fig, axarr = plt.subplots(1, 1, figsize=(6, 6))\n",
        "axarr.axis('off')\n",
        "axarr.imshow(I)\n",
        "plt.tight_layout(h_pad=0.1, w_pad=0.1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}