{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Edusat_Data_8_classes 15_May_2021_Version_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1rl0_0AxGrHEUaq8pi-vNW80uJxtFM_Tx",
      "authorship_tag": "ABX9TyNAD4DiLMbJoy/GtNTMnmH5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BRIJNANDA1979/CNN-Sentinel/blob/master/CNN_Edusat_Data_8_classes_15_May_2021_Version_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PdKw1IFO_kG",
        "outputId": "17e54fcd-b59a-42f8-a54d-50a10eaae861"
      },
      "source": [
        "\"\"\"\n",
        "Created on Thu May 13 03:02:04 2021\n",
        "\n",
        "@author: BRIJB\n",
        "\"\"\"\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# import the needed packages\n",
        "import tensorflow as tf\n",
        "from keras import losses \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import tensorflow.keras as keras\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from keras.models import model_from_json\n",
        "import os\n",
        "\n",
        "batch_size = 30\n",
        "\n",
        "# define and move to dataset directory\n",
        "datasetdir = \"/content/drive/MyDrive/Data/Sentinel 2 Data for CNN/EuroSAT/2750\"\n",
        "import os\n",
        "os.chdir(datasetdir)\n",
        "\n",
        "\n",
        "\n",
        "# shortcut to the ImageDataGenerator class\n",
        "ImageDataGenerator = keras.preprocessing.image.ImageDataGenerator\n",
        "gen = ImageDataGenerator()\n",
        "iterator = gen.flow_from_directory(\n",
        "    os.getcwd(), \n",
        "    target_size=(256,256), \n",
        "    classes=('Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential','SeaLake')\n",
        "    \n",
        ")\n",
        "# we can guess that the iterator has a next function, \n",
        "# because all python iterators have one. \n",
        "batch = iterator.next()\n",
        "print(len(batch))\n",
        "print(type(batch[0]))\n",
        "print(batch[0].shape)\n",
        "print(batch[0].dtype)\n",
        "#print(batch[0].max())\n",
        "#print(batch[1].shape)\n",
        "#print(batch[1].dtype)\n",
        "#print(type(batch[1]))\n",
        "#the first element is an array of 32 images with 64X64 pixels, and 3 color channels, encoded as floats in the range 0 to 255\n",
        "#The second element contains the 32 corresponding labels.\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 16579 images belonging to 8 classes.\n",
            "2\n",
            "<class 'numpy.ndarray'>\n",
            "(32, 256, 256, 3)\n",
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4jLiUltPUGm",
        "outputId": "b967dba6-7a0d-4b3d-c53a-c9689fc84a01"
      },
      "source": [
        "batch = iterator.next()\n",
        "print(len(batch))\n",
        "print(type(batch[1]))\n",
        "print(batch[1].shape)\n",
        "print(batch[1].dtype)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "<class 'numpy.ndarray'>\n",
            "(32, 8)\n",
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUm4Y-MHQJVD",
        "outputId": "0c1b32ee-13a9-4eb3-ce3b-1316598ef3b9"
      },
      "source": [
        "#Augmentation by Flipping images\n",
        "#Now, let's make the transformation a bit more complex. This time, the ImageDataGenerator will flip, zoom, and rotate the images on a random basis   \n",
        "imgdatagen = ImageDataGenerator(\n",
        "    rescale = 1/255., \n",
        "    horizontal_flip = True, \n",
        "    zoom_range = 0.3, \n",
        "    rotation_range = 15.,\n",
        "    validation_split = 0.1,\n",
        ")\n",
        "batch_size = 30\n",
        "height, width = (256,256)\n",
        "train_dataset = imgdatagen.flow_from_directory(\n",
        "    os.getcwd(),\n",
        "    target_size = (height, width), \n",
        "    classes = ('Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential','SeaLake'),\n",
        "    batch_size = batch_size,\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "val_dataset = imgdatagen.flow_from_directory(\n",
        "    os.getcwd(),\n",
        "    target_size = (height, width), \n",
        "    classes = ('Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential','SeaLake'),\n",
        "    batch_size = batch_size,\n",
        "    subset = 'validation'\n",
        ")\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "initializers = {\n",
        "    \n",
        "}\n",
        "model.add( \n",
        "    keras.layers.Conv2D(\n",
        "        24, 5, input_shape=(256,256,3), \n",
        "        activation='relu', \n",
        "    )\n",
        ")\n",
        "model.add( keras.layers.MaxPooling2D(2) )\n",
        "model.add( \n",
        "    keras.layers.Conv2D(\n",
        "        48, 5, activation='relu', \n",
        "    )\n",
        ")\n",
        "model.add( keras.layers.MaxPooling2D(2) )\n",
        "model.add( \n",
        "    keras.layers.Conv2D(\n",
        "        96, 5, activation='relu', \n",
        "    )\n",
        ")\n",
        "model.add( keras.layers.Flatten() )\n",
        "model.add( keras.layers.Dropout(0.2) )\n",
        "\n",
        "model.add( keras.layers.Dense(\n",
        "    8, activation='softmax',\n",
        "    )\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=keras.optimizers.RMSprop(lr=0.001),\n",
        "              metrics=['acc'])\n",
        "\n",
        "model.fit_generator(\n",
        "    train_dataset, \n",
        "    validation_data = val_dataset,\n",
        "    workers=10,\n",
        "    epochs=10,\n",
        ")\n",
        "\n",
        "# serialize model to JSON https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14922 images belonging to 8 classes.\n",
            "Found 1657 images belonging to 8 classes.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 252, 252, 24)      1824      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 126, 126, 24)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 122, 122, 48)      28848     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 61, 61, 48)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 57, 57, 96)        115296    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 311904)            0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 311904)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 2495240   \n",
            "=================================================================\n",
            "Total params: 2,641,208\n",
            "Trainable params: 2,641,208\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "374/498 [=====================>........] - ETA: 10:42 - loss: 0.5282 - acc: 0.2917"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}